{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logica del Juego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "from termcolor import colored, cprint\n",
    "import time\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = empty_space; 1 = player; 2 = goal \n",
    "def draw_map(size, player_position, goal_position):\n",
    "    map = np.zeros((size[1], size[0]), dtype=np.int)\n",
    "    map[player_position[1], player_position[0]] = 1\n",
    "    map[goal_position[1], goal_position[0]] = 2\n",
    "    \n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GameEnviroment:\n",
    "    def __init__(self, map, size, player_initial_state, goal_position):\n",
    "        self.map = map\n",
    "        self.size = size\n",
    "        self.player_state = player_initial_state\n",
    "        self.goal = goal_position \n",
    "        self.rewards = {\n",
    "            \"walk\": -1,\n",
    "            \"fall\": -5,\n",
    "            \"goal\": 20\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.map) + f\"\\nPlayerPos: ({self.player_state[0]}, {self.player_state[1]})\"\n",
    "    \n",
    "    def reset(self, initial_map, player_initial_state):\n",
    "        self.map = initial_map\n",
    "        self.player_state = player_initial_state\n",
    "        return ((10 * self.player_state[0]) + self.player_state[1])\n",
    "\n",
    "    def is_in_goal(self):\n",
    "        return (self.player_state[0] == self.goal[0] and self.player_state[1] == self.goal[1])\n",
    "    \n",
    "    def has_fallen_of_map(self):\n",
    "        x_range = np.array(range(self.size[0]))\n",
    "        y_range = np.array(range(self.size[1]))\n",
    "        return (self.player_state[1] not in y_range or self.player_state[0] not in x_range)\n",
    "\n",
    "    def move_player_left(self):\n",
    "        self.player_state[0] = self.player_state[0] - 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "    \n",
    "    def move_player_right(self):\n",
    "        self.player_state[0] = self.player_state[0] + 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "\n",
    "    def move_player_up(self):\n",
    "        self.player_state[1] = self.player_state[1] - 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "    \n",
    "    def move_player_down(self):\n",
    "        self.player_state[1] = self.player_state[1] + 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "        \n",
    "    # 0 = LEFT, 1 = RIGHT, 2 = UP, 3 = DOWN\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            new_state, reward, done = self.move_player_left()\n",
    "        if action == 1:\n",
    "            new_state, reward, done = self.move_player_right()\n",
    "        if action == 2:\n",
    "            new_state, reward, done = self.move_player_up()\n",
    "        if action == 3:\n",
    "            new_state, reward, done = self.move_player_down()\n",
    "\n",
    "        # applying wind\n",
    "        PrA = 0.1\n",
    "        PrB = 0.2\n",
    "        PrC = 0.15\n",
    "        if self.player_state[0] == 3:\n",
    "            random_number = np.random.uniform(low=0.0, high=1.0)\n",
    "            if random_number <= PrA:\n",
    "                new_state, reward, done = self.move_player_up()\n",
    "        \n",
    "        if self.player_state[0] == 4:\n",
    "            random_number = np.random.uniform(low=0.0, high=1.0)\n",
    "            if random_number <= PrB:\n",
    "                new_state, reward, done = self.move_player_up()\n",
    "                new_state, reward, done = self.move_player_up()\n",
    "\n",
    "        if self.player_state[0] == 5:\n",
    "            random_number = np.random.uniform(low=0.0, high=1.0)\n",
    "            if random_number <= PrC:\n",
    "                new_state, reward, done = self.move_player_up()\n",
    "        \n",
    "        return new_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "PlayerPos: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "map_size = [9, 7]\n",
    "player_initial_pos = [1, 1]\n",
    "goal_pos = [7, 4]\n",
    "\n",
    "initial_map = draw_map(map_size, player_initial_pos, goal_pos)\n",
    "env = GameEnviroment(initial_map, map_size, player_initial_pos, goal_pos)\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializando parametros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 15000\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "learning_rate = 0.2\n",
    "discount_rate = 0.95\n",
    "\n",
    "rewards_avg = []\n",
    "\n",
    "action_space_size = 4\n",
    "state_space_size = 200\n",
    "\n",
    "q_table = np.zeros((state_space_size, action_space_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corriendo el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average  0\n",
      "average  1\n",
      "average  2\n",
      "average  3\n",
      "average  4\n",
      "average  5\n",
      "average  6\n",
      "average  7\n",
      "average  8\n",
      "average  9\n",
      "average  10\n",
      "average  11\n",
      "average  12\n",
      "average  13\n",
      "average  14\n",
      "average  15\n",
      "average  16\n",
      "average  17\n",
      "average  18\n",
      "average  19\n",
      "average  20\n",
      "average  21\n",
      "average  22\n",
      "average  23\n",
      "average  24\n",
      "average  25\n",
      "average  26\n",
      "average  27\n",
      "average  28\n",
      "average  29\n",
      "average  30\n",
      "average  31\n",
      "average  32\n",
      "average  33\n",
      "average  34\n",
      "average  35\n",
      "average  36\n",
      "average  37\n",
      "average  38\n",
      "average  39\n",
      "average  40\n",
      "average  41\n",
      "average  42\n",
      "average  43\n",
      "average  44\n",
      "average  45\n",
      "average  46\n",
      "average  47\n",
      "average  48\n",
      "average  49\n",
      "average  50\n",
      "average  51\n",
      "average  52\n",
      "average  53\n",
      "average  54\n",
      "average  55\n",
      "average  56\n",
      "average  57\n",
      "average  58\n",
      "average  59\n",
      "average  60\n",
      "average  61\n",
      "average  62\n",
      "average  63\n",
      "average  64\n",
      "average  65\n",
      "average  66\n",
      "average  67\n",
      "average  68\n",
      "average  69\n",
      "average  70\n",
      "average  71\n",
      "average  72\n",
      "average  73\n",
      "average  74\n",
      "average  75\n",
      "average  76\n",
      "average  77\n",
      "average  78\n",
      "average  79\n",
      "average  80\n",
      "average  81\n",
      "average  82\n",
      "average  83\n",
      "average  84\n",
      "average  85\n",
      "average  86\n",
      "average  87\n",
      "average  88\n",
      "average  89\n",
      "average  90\n",
      "average  91\n",
      "average  92\n",
      "average  93\n",
      "average  94\n",
      "average  95\n",
      "average  96\n",
      "average  97\n",
      "average  98\n",
      "average  99\n"
     ]
    }
   ],
   "source": [
    "# This cycle is to calculate the average reward/episodes and its only purpose is to plot the nice graph below that\n",
    "# shows how the agent learn how to maximize the reward.\n",
    "for it in range(100):\n",
    "    print('average ', it)\n",
    "    rewards_all_episodes=[]\n",
    "    \n",
    "    # exporation-exploitation trade-off params\n",
    "    exploration_rate = 1\n",
    "    max_exploration_rate = 1\n",
    "    min_exploration_rate = 0.01\n",
    "    exploration_decay_rate = 0.005\n",
    "    \n",
    "    # init q table in zeros\n",
    "    q_table = np.zeros((state_space_size, action_space_size))\n",
    "\n",
    "    # iterate over the episodes\n",
    "    for episode in range(num_episodes):\n",
    "        player_initial_pos = [1, 1]\n",
    "        initial_map = draw_map(map_size, player_initial_pos, goal_pos)\n",
    "        state = env.reset(initial_map, player_initial_pos)\n",
    "        done = False\n",
    "        rewards_current_episode = 0\n",
    "        \n",
    "        # iterate over the steps for an episode\n",
    "        for step in range(max_steps_per_episode):\n",
    "            # Exploration-exploitation trade-off\n",
    "            exploration_rate_threshold = np.random.uniform(low=0.0, high=1.0)\n",
    "            if exploration_rate_threshold <= exploration_rate:\n",
    "                # Expl oration time\n",
    "                action = np.random.randint(0, action_space_size)\n",
    "            else:\n",
    "                # Explotation time\n",
    "                action = np.argmax(q_table[state])\n",
    "\n",
    "            # Take action\n",
    "            new_state, reward, done = env.step(action)\n",
    "\n",
    "            # Update Q-table for Q(s,a)\n",
    "            if done == True: \n",
    "                break\n",
    "            q_table[state, action] = (1 - learning_rate) * q_table[state, action] + learning_rate * (reward + discount_rate * np.max(q_table[new_state]))\n",
    "            # transition next state\n",
    "\n",
    "            state = new_state\n",
    "            rewards_current_episode += reward\n",
    "\n",
    "\n",
    "        # Exploration rate decay\n",
    "        exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate) * (math.e ** (-exploration_decay_rate * episode))\n",
    "\n",
    "        rewards_all_episodes.append(rewards_current_episode)\n",
    "    rewards_avg.append(rewards_all_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x296cdefce50>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(0,num_episodes)]\n",
    "y = np.mean(rewards_avg, axis=0)\n",
    "plot.xlabel('Episodes')\n",
    "plot.ylabel('Reward')\n",
    "plot.plot(x, y,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************q-table**************** \n",
      " [[ 0.         -0.91410065  0.         -0.83222784]\n",
      " [ 0.         -1.95       -0.99999701 -0.99999997]\n",
      " [ 0.         -1.77403268 -0.95601953 -0.94502442]\n",
      " [ 0.         -0.36       -0.36       -0.67232   ]\n",
      " [ 0.         -0.5868     -0.36       -0.2       ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.99622211 -0.99900965  0.         -1.94142676]\n",
      " [-1.         -1.94998911 -1.         -1.94999995]\n",
      " [-1.         -2.20969942 -1.92328685 -1.38966985]\n",
      " [-0.737856   -1.32203929 -1.4137532  -0.8547808 ]\n",
      " [-0.5904     -0.63544    -0.801216   -0.5904    ]\n",
      " [ 0.          0.         -0.488      -0.36      ]\n",
      " [ 0.         -0.2        -0.2         0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.83222784 -0.93128052  0.         -1.67045764]\n",
      " [-1.77263712 -1.56512582 -0.99999902 -2.04879797]\n",
      " [-1.5824375  -1.54526916 -1.65795389 -1.60527842]\n",
      " [-1.1347679  -1.07251782 -1.19018306 -0.99912384]\n",
      " [-0.76504    -0.526      -0.73059264 -0.36      ]\n",
      " [ 0.         -0.36       -0.2684     -0.2       ]\n",
      " [-0.36        0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.488      -0.67232     0.         -1.03192371]\n",
      " [-0.99337955 -0.95534784 -0.89262582 -0.93133955]\n",
      " [-1.42155391 -1.01409523 -0.93416128 -0.936292  ]\n",
      " [-1.22402496 -0.66602    -0.96734364 -0.6284    ]\n",
      " [-0.36       -0.36       -0.2        -0.5564    ]\n",
      " [-0.36       -0.36       -0.2        -0.36      ]\n",
      " [-0.2         0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.488      -0.36        0.         -0.4284    ]\n",
      " [-1.03587143 -0.5904     -0.36       -0.398     ]\n",
      " [-0.55578755 -0.36       -0.839216   -0.53322   ]\n",
      " [-0.4284     -0.526      -0.3904     -0.410996  ]\n",
      " [-0.238       0.         -0.2        -0.2       ]\n",
      " [-0.238       0.          0.         -0.36      ]\n",
      " [ 0.         -0.36        0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.2        -0.2         0.          0.        ]\n",
      " [-0.4284     -0.36       -0.2        -0.488     ]\n",
      " [-0.36       -0.36       -0.36       -0.2       ]\n",
      " [-0.398      -0.2        -0.3904     -0.2       ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -0.2       ]\n",
      " [ 0.         -0.2         0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.36       -0.2         0.         -0.2       ]\n",
      " [-0.238      -0.2        -0.36        0.        ]\n",
      " [ 0.          0.          0.         -0.36      ]\n",
      " [-0.238       0.          0.         -0.36      ]\n",
      " [-0.2         0.          0.         -0.2       ]\n",
      " [-0.2         0.          0.         -0.2       ]\n",
      " [-0.2         0.         -0.2         0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.2         0.          0.          0.        ]\n",
      " [-0.2         0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"*****************q-table**************** \\n {q_table}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25c701cf35b356b2d4bd1cf9d31da66e110c57249d3d7829e193c9302586500a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
