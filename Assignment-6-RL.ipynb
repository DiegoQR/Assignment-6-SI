{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logica del Juego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Qui√±ones Rudon Diego Alejandro\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "from termcolor import colored, cprint\n",
    "import time\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = empty_space; 1 = player; 2 = goal \n",
    "def draw_map(size, player_position, goal_position):\n",
    "    map = np.zeros((size[1], size[0]), dtype=np.int)\n",
    "    map[player_position[1], player_position[0]] = 1\n",
    "    map[goal_position[1], goal_position[0]] = 2\n",
    "    \n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GameEnviroment:\n",
    "    def __init__(self, map, size, player_initial_state, goal_position):\n",
    "        self.map = map\n",
    "        self.size = size\n",
    "        self.player_state = player_initial_state\n",
    "        self.goal = goal_position \n",
    "        self.rewards = {\n",
    "            \"walk\": -1,\n",
    "            \"fall\": -5,\n",
    "            \"goal\": 20\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.map) + f\"\\nPlayerPos: ({self.player_state[0]}, {self.player_state[1]})\"\n",
    "    \n",
    "    def reset(self, initial_map, player_initial_state):\n",
    "        self.map = initial_map\n",
    "        self.player_state = player_initial_state\n",
    "        return ((10 * self.player_state[0]) + self.player_state[1])\n",
    "\n",
    "    def is_in_goal(self):\n",
    "        return (self.player_state[0] == self.goal[0] and self.player_state[1] == self.goal[1])\n",
    "    \n",
    "    def has_fallen_of_map(self):\n",
    "        x_range = np.array(range(self.size[0]))\n",
    "        y_range = np.array(range(self.size[1]))\n",
    "        return (self.player_state[1] not in y_range or self.player_state[0] not in x_range)\n",
    "\n",
    "    def move_player_left(self):\n",
    "        self.player_state[0] = self.player_state[0] - 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "    \n",
    "    def move_player_right(self):\n",
    "        self.player_state[0] = self.player_state[0] + 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "\n",
    "    def move_player_up(self):\n",
    "        self.player_state[1] = self.player_state[1] - 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "    \n",
    "    def move_player_down(self):\n",
    "        self.player_state[1] = self.player_state[1] + 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "        \n",
    "    # 0 = LEFT, 1 = RIGHT, 2 = UP, 3 = DOWN\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            new_state, reward, done = self.move_player_left()\n",
    "        if action == 1:\n",
    "            new_state, reward, done = self.move_player_right()\n",
    "        if action == 2:\n",
    "            new_state, reward, done = self.move_player_up()\n",
    "        if action == 3:\n",
    "            new_state, reward, done = self.move_player_down()\n",
    "\n",
    "        # applying wind\n",
    "        PrA = 0.1\n",
    "        PrB = 0.2\n",
    "        PrC = 0.15\n",
    "        if self.player_state[0] == 3:\n",
    "            random_number = np.random.uniform(low=0.0, high=1.0)\n",
    "            if random_number <= PrA:\n",
    "                new_state, reward, done = self.move_player_up()\n",
    "        \n",
    "        if self.player_state[0] == 4:\n",
    "            random_number = np.random.uniform(low=0.0, high=1.0)\n",
    "            if random_number <= PrB:\n",
    "                new_state, reward, done = self.move_player_up()\n",
    "                new_state, reward, done = self.move_player_up()\n",
    "\n",
    "        if self.player_state[0] == 5:\n",
    "            random_number = np.random.uniform(low=0.0, high=1.0)\n",
    "            if random_number <= PrC:\n",
    "                new_state, reward, done = self.move_player_up()\n",
    "        \n",
    "        return new_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "PlayerPos: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "map_size = [9, 7]\n",
    "player_initial_pos = [1, 1]\n",
    "goal_pos = [7, 4]\n",
    "\n",
    "initial_map = draw_map(map_size, player_initial_pos, goal_pos)\n",
    "env = GameEnviroment(initial_map, map_size, player_initial_pos, goal_pos)\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializando parametros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 15000\n",
    "max_steps_per_episode = 200\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount_rate = 0.95\n",
    "\n",
    "rewards_avg = []\n",
    "\n",
    "action_space_size = 4\n",
    "state_space_size = 200\n",
    "\n",
    "q_table = np.zeros((state_space_size, action_space_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corriendo el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average  0\n",
      "average  1\n",
      "average  2\n",
      "average  3\n",
      "average  4\n",
      "average  5\n",
      "average  6\n",
      "average  7\n",
      "average  8\n",
      "average  9\n",
      "average  10\n",
      "average  11\n",
      "average  12\n",
      "average  13\n",
      "average  14\n",
      "average  15\n",
      "average  16\n",
      "average  17\n",
      "average  18\n",
      "average  19\n",
      "average  20\n",
      "average  21\n",
      "average  22\n",
      "average  23\n",
      "average  24\n",
      "average  25\n",
      "average  26\n",
      "average  27\n",
      "average  28\n",
      "average  29\n",
      "average  30\n",
      "average  31\n",
      "average  32\n",
      "average  33\n",
      "average  34\n",
      "average  35\n",
      "average  36\n",
      "average  37\n",
      "average  38\n",
      "average  39\n",
      "average  40\n",
      "average  41\n",
      "average  42\n",
      "average  43\n",
      "average  44\n",
      "average  45\n",
      "average  46\n",
      "average  47\n",
      "average  48\n",
      "average  49\n",
      "average  50\n",
      "average  51\n",
      "average  52\n",
      "average  53\n",
      "average  54\n",
      "average  55\n",
      "average  56\n",
      "average  57\n",
      "average  58\n",
      "average  59\n",
      "average  60\n",
      "average  61\n",
      "average  62\n",
      "average  63\n",
      "average  64\n",
      "average  65\n",
      "average  66\n",
      "average  67\n",
      "average  68\n",
      "average  69\n",
      "average  70\n",
      "average  71\n",
      "average  72\n",
      "average  73\n",
      "average  74\n",
      "average  75\n",
      "average  76\n",
      "average  77\n",
      "average  78\n",
      "average  79\n",
      "average  80\n",
      "average  81\n",
      "average  82\n",
      "average  83\n",
      "average  84\n",
      "average  85\n",
      "average  86\n",
      "average  87\n",
      "average  88\n",
      "average  89\n",
      "average  90\n",
      "average  91\n",
      "average  92\n",
      "average  93\n",
      "average  94\n",
      "average  95\n",
      "average  96\n",
      "average  97\n",
      "average  98\n",
      "average  99\n"
     ]
    }
   ],
   "source": [
    "# This cycle is to calculate the average reward/episodes and its only purpose is to plot the nice graph below that\n",
    "# shows how the agent learn how to maximize the reward.\n",
    "for it in range(100):\n",
    "    print('average ', it)\n",
    "    rewards_all_episodes=[]\n",
    "    \n",
    "    # exporation-exploitation trade-off params\n",
    "    exploration_rate = 1\n",
    "    max_exploration_rate = 1\n",
    "    min_exploration_rate = 0.01\n",
    "    exploration_decay_rate = 0.005\n",
    "    \n",
    "    # init q table in zeros\n",
    "    q_table = np.zeros((state_space_size, action_space_size))\n",
    "\n",
    "    # iterate over the episodes\n",
    "    for episode in range(num_episodes):\n",
    "        player_initial_pos = [1, 1]\n",
    "        initial_map = draw_map(map_size, player_initial_pos, goal_pos)\n",
    "        state = env.reset(initial_map, player_initial_pos)\n",
    "        done = False\n",
    "        rewards_current_episode = 0\n",
    "        \n",
    "        # iterate over the steps for an episode\n",
    "        for step in range(max_steps_per_episode):\n",
    "            # Exploration-exploitation trade-off\n",
    "            exploration_rate_threshold = np.random.uniform(low=0.0, high=1.0)\n",
    "            if exploration_rate_threshold <= exploration_rate:\n",
    "                # Expl oration time\n",
    "                action = np.random.randint(0, action_space_size)\n",
    "            else:\n",
    "                # Explotation time\n",
    "                action = np.argmax(q_table[state])\n",
    "\n",
    "            # Take action\n",
    "            new_state, reward, done = env.step(action)\n",
    "\n",
    "            # Update Q-table for Q(s,a)\n",
    "            q_table[state, action] = (1 - learning_rate) * q_table[state, action] + learning_rate * (reward + discount_rate * np.max(q_table[new_state]))\n",
    "            # transition next state\n",
    "\n",
    "            state = new_state\n",
    "            rewards_current_episode += reward\n",
    "\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "\n",
    "        # Exploration rate decay\n",
    "        exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate) * (math.e ** (-exploration_decay_rate * episode))\n",
    "\n",
    "        rewards_all_episodes.append(rewards_current_episode)\n",
    "    rewards_avg.append(rewards_all_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x296d02d2a30>]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAa80lEQVR4nO3dfZRcdZ3n8fenOx3ooJJEgoZACCATBgQJ9OFhcF1RZoIPI4HRARZ2nH3iuIPHUWfiJEtmxXPgqJOZ0TPj7Eh0VUYYEEVaFhzDg6yedXmwMUCCkCU8p8NII8QHEkmn+7t/3Nuhuh66b6fr1r3p+3mdU6erfvdW3U9Vd99v3affTxGBmZlZra6iA5iZWfm4OJiZWQMXBzMza+DiYGZmDVwczMyswayiA7TDQQcdFEuWLCk6hpnZPuX+++9/ISIWNJs2I4rDkiVLGBgYKDqGmdk+RdLTraZ5t5KZmTVwcTAzswYuDmZm1sDFwczMGrg4mJlZgxlxtpKZTa5/wyBr129m2/adHDK3l5XLl7Ji2aKiY7XNVN/fTP88pkszoVfWvr6+2BdPZa3KH+fY+xzcvhMBY39x8+b08MnfPy7TP/Dg9p10S4xEsCjjZ1X73DHdEheeehhXrDi+5fx78/to9lxgT9uBvT1I8NKO4abvYyrL3puca/o3cu09z1D73y7gotMWc8WK48e95v49Xbyye5TRePXzAhqeP+aA2d1cee7xTd/v9h3D4z6Py29+mO07h4FXf/+1zztkbi9nHrOAux4dGvf4xvu3snN4FIAuwb87dfG432H/hkE+/o0HGK3L1iUYDVhU97oH9vbw8q7dDI80X/+Nvadmv5v6fM1+h80+w4n+5ur/N5p9trWfXTNHH3wAt3/87S2nNyPp/ojoazrNxSEf/RsGx/0y5/Qke/B2pH/gPV0wXP+XTPIPq/QPulvitCPncd+TL46bd79ZyR9evQNmd7Nj18i4f8wDe3t4+ZXhpsuqX+6++pcwu1vsSv/J583p4diFr+VHj79YcCqzzptqgZioOHi3UpvUfms4sLenocLvqFs7t1pZBzBWr0cimq7kmhUGgJd3jQCMW/ZE3zTql7uv2lXz7e+lHcMuDFZZjz3/cttey8VhGuq3DsZkXSGbmZWVi8MUtCoGZmYzjYtDRv0bBln5zQcZHt2Xd8CYmWXj6xwyWrt+swuDmVWGi0NGtadDmpnNdC4OGazp31h0BDOzjiq0OEj6iqTnJW2qaZsv6XZJj6U/5xWZcU3/Rq6555kiI5iZZfL5809s22sVveXwNeDsurZVwJ0RcTRwZ/q4MC4MZrYv6OmirT0sFFocIuKHQP0VS+cAV6f3rwZWdDKTmdm+pkuw9gMntvc12/pq7fGGiHgOIP15cLOZJF0iaUDSwNDQUC5B+jcM5vK6ZtY5c3t7mDenB0i6icmiK+uMOcoaYd6cHv72D09se79s++x1DhGxDlgHSd9KeSzjL258KI+XNbM6Zxw1n//7+It7unHpFtT2iSfgd46az8PbfjXpRagTdejYv2GQP7vhQUaa9Cm3aG4vP1r1jnHzrv72RnYOj+xp6+3p5g9OXsQtDz7X0IFgq+U162ywft5WHTfWP/c9Jyxs2ulfHspYHH4maWFEPCdpIfB8ESHW9G9s2YeRVcfsbjGrSw19Y7Uyt7eHXbtHms4vYO6cnj0dIjbrtXRsBTHRt52LT1tM3+Hzm/ZWe+YxC8atuGqNdUpYuxKeKgFPfuY9medv1VPpmKw97GZ5/Swry7FpzVb6Y7+D+nmbvX6zHlZbLS/Le2s1X5G9NBfeK6ukJcAtEfHm9PFa4OcR8RlJq4D5EfGJiV4jj15Zj1h16z7dGZ1N3WRdiDf7Jlnb7XX9vNPpjv2Mz3y/6bU19d9up6u+w8ixgtWVFpy8l1+UqnSXP5nSdtkt6Trg7cBBwM+ATwL9wA3AYuAZ4AMRMWE3m3kUhyWrbm3r67Vbl2D/WV2Zv9GOybtr7p4u8Zr9Z/HSjok3/Zt9w67t379+JVyrtj//Vpv+nz6veV/8E40rkGXl0KmVymTvK29FL986o7TFoV3aXRz6Nwzy0W880LbXa4exlW7tboiJVn6T/WNP1lfU2K6KiXZZdNWMO9FsEJ7prGDyHvxmX1D0+yp6+ZY/F4cparVJn0UXNIxGNdEKsdWyavdP780/ZpZ/7Fa9zLbzG6JXMGbl5eIwRXu7S+nz55+4V0M+Fr357hW4WTV5JLgOuPi0xXtWqFnPUBibF5qfEdEpU8lrZtXg4tAGFzc5W2UqvHI2s7JxcZimsV1JZmYzSRm7z9hn1O5KMjObSVwcpmE6u5LMzMrMxWEvtbPfdDOzsnFx2EvenWRmM5mLw17o8admZjOcV3N7YWTfv27QzGxCLg51sgzw06I7IjOzGcPFoc7a9ZsnnadbJRgmyswsRy4OdbJ0uHfhqYd1IImZWXFcHKaot6fL1zeY2Yzn4jBFnz7vhKIjmJnlzsVhinx9g5lVgYtDHR9qNjNzcWjgs1TNzFwcpsRbFWZWFS4OU+CtCjOrCheHKVg0t7foCGZmHeHiMAUrly8tOoKZWUeUdphQSU8BvwJGgN0R0VdsIp/GambVUdrikDozIl4oOoSZWdV4t5KZmTUoc3EI4DZJ90u6pH6ipEskDUgaGBoaKiCemdnMVebicEZEnAS8C7hU0ttqJ0bEuojoi4i+BQsWFJPQzGyGKm1xiIht6c/ngZuAU4pNZGZWHaUsDpIOkPTasfvA7wGbik1lZlYdZT1b6Q3ATUpGXJsF/HNEfK/YSGZm1VHK4hARTwBvKTqHmVlVlXK3kpmZFcvFwczMGrg4mJlZAxeHGv0bBouOYGZWCi4ONdau31x0BDOzUnBxqLFt+86iI5iZlYKLQ41DPJiPmRng4jCOB/MxM0u4ONTwYD5mZgkXBzMza+DiUGNN/8aiI5iZlYKLQ43r7n226AhmZqXg4lBjJKLoCGZmpeDiYGZmDVwczMysgYtDjXlzeoqOYGZWCi4ONX4zPNJy2txeFw4zqw4Xhxo7h0dbTnvvWxZ2MImZWbFcHDK669GhoiOYmXWMi0NG7rHVzKrExSEj99hqZlXi4pCRe2w1syopbXGQdLakzZK2SFpVdB732GpmVVLK4iCpG/gH4F3AscCFko4tNpWZWXWUsjgApwBbIuKJiNgFXA+cU3AmM7PKKGtxWATUdpG6NW3bQ9IlkgYkDQwN+TRTM7N2KmtxUJO2cV2mRsS6iOiLiL4FCxa0ZaE9LT6NVu1mZjNVWVd7W4HDah4fCmzLe6GtLpCe4MJpM7MZqazF4cfA0ZKOkDQbuAC4Oe+Fqtn2ygTtZmYz1ayiAzQTEbslfRhYD3QDX4mIh/Nf7tTazcxmqlIWB4CI+C7w3aJzmJlVUVl3K5mZWYFcHMzMrIGLg5mZNXBxMDOzBhMekJZ00kTTI+In7Y1jZmZlMNnZSn+T/twf6AMeJLl6+QTgXuCt+UUzM7OiTLhbKSLOjIgzgaeBk9LuKk4GlgFbOhGwk9x9hplZIutq75iI2Dj2ICI2ASfmkqhAu1tc7Naq3cxspsp6Edyjkr4MXEPSAd7FwCO5pSqIr5A2M0tkLQ5/DPxX4E/Txz8E/jGPQGZmVrxJi0M6KtstEXEW8Ln8I5mZWdEmPeYQESPADkkHdiCPmZmVQNbdSr8BNkq6HXh5rDEiPpJLKjMzK1TW4nBrejMzswrIVBwi4uq8g5iZWXlkKg6SjgY+DRxLcrU0ABFxZE65CiE1P23VI8GZWdVkvQjuqySnru4GzgT+Cfh6XqGKctGpi6fUbmY2U2UtDr0RcSegiHg6Ii4H3pFfrGL0HT6/oauMM46azxUrji8mkJlZQbIWh99I6gIek/RhSecCB+eYq+P6Nwyy8psPMjw6vv3uJ16kf8NgMaHMzAqStTh8FJgDfAQ4maT7jA/mlKkQa9dvZni08YDDaMDlNz9cQCIzs+JkPZX15xHxa+DXwH/IMU9htm3f2XLa9p3DHUxiZla8rFsOX5P0uKTrJf2JpBm3E/6Qub1FRzAzK41MxSEi3gb8NvD3wDzgVkkv5hms01YuX9py2gGzuzuYxMyseJmKg6S3An8GXAa8B7gFuDSPQJIulzQo6YH09u48llNvxbJFdLe4nmHX7pFORDAzK42sxxx+AAyQXAj33YjYlV8kAD4XEX+d8zIajLQYt6H+DCYzs5kua3F4PXAG8DbgI5JGgbsj4i9zS9ZhF33p7qIjmJmVRtZjDtuBJ4AngeeAo0gKRV4+LOkhSV+RNK/ZDJIukTQgaWBoaGjaC/zR4zPqEIqZ2bRkPebwOPA3wHzgi8DSiPi3e7tQSXdI2tTkdg5JNx1HkYxR/Vy63AYRsS4i+iKib8GCBXsbxczMmsi6W+noiGjbnvd0VLlJSfoSycFvMzProKzXObxJ0p2SNgFIOkHSmjwCSVpY8/BcYFMeyzEzs9ayFocvAauBYYCIeAi4IKdMfyVpo6SHSHqA/VhOy8msy112m1nFZN2tNCci7tP4gQ1255CHiPj3ebzuZBbN7WWwRRcar9u/p8NpzMyKlXXL4QVJRwEBIOn9JAeLZ4wzj2l9UPsX7lvJzCom65bDpcA64BhJgySntF6UW6oC3PVo69Nh3e+SmVVN1jGknwDOknQAydbGTuB84Okcs3VUq11KMHG/S2ZmM9GEu5UkvU7SaklfkPS7wA6ScRy2AH/YiYBlsGLZoqIjmJl11GRbDl8HXgLuBv4L8AlgNrAiIh7IN5qZmRVlsuJwZEQcDyDpy8ALwOKI+FXuyczMrDCTna205zSdiBgBnnRhMDOb+SbbcniLpF+m9wX0po8FRES8Ltd0ZmZWiAmLQ0R4CDQzswrKehFcpfVvGCw6gplZR7k4ZLB2/eaiI5iZdZSLQwbbJrhAzsxsJnJxyMDdZ5hZ1bg4ZODuM8ysalwcMnD3GWZWNS4OZmbWwMUhNaen+UfRqt3MbCbzmi+1c3h0Su1mZjOZi0Oq1RlJPlPJzKrIxSG1cvlSerrGjZFNT5d8ppKZVZKLQ42RiAkfm5lVhYtD6rKbNjJaVwtGI2k3M6saF4fUy7tGptRuZjaTFVIcJH1A0sOSRiX11U1bLWmLpM2Slnciz5p+bx2YmdWabLCfvGwCzgOuqm2UdCxwAXAccAhwh6TfSkehy8219zyT58ubme1zCtlyiIhHIqJZP9jnANdHxCsR8SSwBTgl9zx5L8DMbB9TtmMOi4Bnax5vTdsaSLpE0oCkgaGhoY6EMzOritx2K0m6A3hjk0mXRcR3Wj2tSVvTL/YRsQ5YB9DX1zetL/9qtRAzs4rKrThExFl78bStwGE1jw8FtrUnUWsuDGZm45Vtt9LNwAWS9pN0BHA0cF/eC53b25P3IszM9ilFncp6rqStwOnArZLWA0TEw8ANwE+B7wGX5n2mEsDwiDvXMzOrVciprBFxE3BTi2lXAld2Mo8vdDMzG69su5XMzKwEXBzMzKyBi4OZmTVwcTAzswYuDmZm1qCojvdKYU3/Rq6799nJZzQzq5jKFoc1/Ru5JkNvrM368zAzm+kqu1sp6xbDRactzjmJmVn5VLY4ZB0f+ooVx+ecxMysfCpbHOT9RWZmLVW2OPTOquxbNzObVGXXkDuG3dmemVkrlS0OZmbWmouDmZk1cHEwM7MGLg5mZtbAxcHMzBq4OJiZWQMXBzMza+DiYGZmDVwczMysgYuDmZk1KKQ4SPqApIcljUrqq2lfImmnpAfS2xeLyGdmVnVFDfazCTgPuKrJtMcj4sTOxjEzs1qFFIeIeARA7jfbzKyUynjM4QhJGyT9QNK/KTqMmVkV5bblIOkO4I1NJl0WEd9p8bTngMUR8XNJJwP9ko6LiF82ef1LgEsAFi/2UJ5mZu2UW3GIiLP24jmvAK+k9++X9DjwW8BAk3nXAesA+vr6so35aWZmmZRqt5KkBZK60/tHAkcDTxSVZ96cnqIWbWZWqKJOZT1X0lbgdOBWSevTSW8DHpL0IPAt4EMR8WIRGQE++fvHFbVoM7NCFXW20k3ATU3abwRu7Hyi5lYsW1R0BDOzQpRqt5KZmZVDZYuDL7EwM2utssXholN9+quZWSuVLQ59h8+fdJ41/Rs7kMTMrHwqWxzWrt886TzX3vNMB5KYmZVPZYvDtu07J53HV9aZWVVVtjgc2OsL3MzMWqlscchyttJ+syr78ZhZxVV27bd9x/Ck8/T2dHcgiZlZ+VS2OBwyt3fSeX6xc/ICYmY2E1W2OKxcvnTSN5+lgJiZzUSVLQ4rli3iwEl6XV25fGmH0piZlUtliwPAS5Mcd3DHe2ZWVZUuDt2TnLLUv2GwQ0nMzMql0sVhJCa+zC3LVdRmZjNRpYvDZLJcRW1mNhO5OEzAZyuZWVVVujhMdpG0z1Yys6qqdHGYM7v1FdAXn7bYZyuZWWVVujjs2DXSctoVK47vYBIzs3KpdHFodUxhkY81mFnFVbo4rFy+lJ7u8UceerrlYw1mVnmVLg5A44g+HuHHzKyY4iBpraRHJT0k6SZJc2umrZa0RdJmScvzzLF2/WaGR8dXg+HR8MVvZlZ5RW053A68OSJOAP4fsBpA0rHABcBxwNnA/5CU26AKrS5y88VvZlZ1hRSHiLgtInanD+8BDk3vnwNcHxGvRMSTwBbglLxytDog7YvfzKzqynDM4T8C/5LeXwQ8WzNta9rWQNIlkgYkDQwNDe3VglcuX9ow2ltvT7cPSJtZ5c3K64Ul3QG8scmkyyLiO+k8lwG7gWvHntZk/qaHiCNiHbAOoK+vb68OI49d5LZ2/Wa2bd/JIXN7Wbl8qS9+M7PKy604RMRZE02X9EHgvcA7I/Z0j7oVOKxmtkOBbfkkTKxYtsjFwMysTlFnK50N/AXwvojYUTPpZuACSftJOgI4GriviIxmZlWW25bDJL4A7AfcrmTAnXsi4kMR8bCkG4CfkuxuujQiWvdxYWZmuSikOETEmyaYdiVwZQfjmJlZnTKcrWRmZiXj4mBmZg0Uk4yjvC+QNAQ8PY2XOAh4oU1x8lD2fFD+jGXPB+XPWPZ84IxTdXhELGg2YUYUh+mSNBARfUXnaKXs+aD8GcueD8qfsez5wBnbybuVzMysgYuDmZk1cHFIrCs6wCTKng/Kn7Hs+aD8GcueD5yxbXzMwczMGnjLwczMGrg4mJlZg0oXB0lnp8ORbpG0qoPLPUzSXZIekfSwpD9N2+dLul3SY+nPeTXPaTp8qqSTJW1Mp/2d0s6q2pSzW9IGSbeUNN9cSd9Kh5x9RNLpJcz4sfR3vEnSdZL2LzqjpK9Iel7Sppq2tmVKO878Rtp+r6Qlbcg35aGF88rXKmPNtD+XFJIOKjLjtEVEJW9AN/A4cCQwG3gQOLZDy14InJTefy3JUKnHAn8FrErbVwGfTe8fm+bbDzgizd2dTrsPOJ1kLIx/Ad7VxpwfB/4ZuCV9XLZ8VwP/Ob0/G5hbpowkA1U9CfSmj28A/rjojMDbgJOATTVtbcsE/AnwxfT+BcA32pDv94BZ6f3PFpmvVca0/TBgPclFuQcVmXHaf7+dXmBZbukvZH3N49XA6oKyfAf4XWAzsDBtWwhsbpYt/eM7PZ3n0Zr2C4Gr2pTpUOBO4B28WhzKlO91JCte1bWXKePYyIbzSTq5vCVdyRWeEVjC+JVv2zKNzZPen0VyNbCmk69u2rnAtUXma5UR+BbwFuApXi0OhWWczq3Ku5UyD0map3RzcRlwL/CGiHgOIP15cDpbq6yL0vv17e3weeATwGhNW5nyHQkMAV9Nd319WdIBZcoYEYPAXwPPAM8Bv4iI28qUsUY7M+15TiRjxf8CeH0bs2YZWrjj+SS9DxiMiAfrJpUm41RUuThkHpI0twDSa4AbgY9GxC8nmrVJW0zQPt1c7wWej4j7sz6lRY48P+NZJJv1/xgRy4CXSXaHtNLxjOl++3NIdiUcAhwg6eKJntIiS5F/q3uTKc/PNOvQwh3NJ2kOcBnw35tNbrG8Qj7DrKpcHDo+JGktST0kheHaiPh22vwzSQvT6QuB5yfJujW9X98+XWcA75P0FHA98A5J15Qo39gyt0bEvenjb5EUizJlPAt4MiKGImIY+DbwOyXLOKadmfY8R9Is4EDgxekG1KtDC18U6f6WEuU7iuRLwIPp/82hwE8kvbFEGaekysXhx8DRko6QNJvkoM/NnVhwekbC/wQeiYi/rZl0M/DB9P4HSY5FjLU3DJ+abv7/StJp6Wv+Uc1z9lpErI6IQyNiCcnn8v2IuLgs+dKM/wo8K2lp2vROkhEES5ORZHfSaZLmpK/9TuCRkmUc085Mta/1fpK/n+l+M5/S0MKdzhcRGyPi4IhYkv7fbCU56eRfy5Jxyjp5gKNsN+DdJGcKPQ5c1sHlvpVkE/Eh4IH09m6SfYp3Ao+lP+fXPOeyNOdmas5UAfqATem0L9Dmg1bA23n1gHSp8gEnAgPp59gPzCthxk8Bj6av/3WSM1YKzQhcR3IMZJhkJfaf2pkJ2B/4JrCF5GycI9uQbwvJPvix/5cvFpWvVca66U+RHpAuKuN0b+4+w8zMGlR5t5KZmbXg4mBmZg1cHMzMrIGLg5mZNXBxMDOzBi4OZjUkjUh6oOY2YW+9kj4k6Y/asNynanvxNCuaT2U1qyHp1xHxmgKW+xTQFxEvdHrZZs14y8Esg/Sb/Wcl3Zfe3pS2Xy7pz9P7H5H0UyVjDlyfts2X1J+23SPphLT99ZJuSzsNvIqavnQkXZwu4wFJVykZV6Nb0teUjAuxUdLHCvgYrEJcHMzG663brXR+zbRfRsQpJFeyfr7Jc1cByyLiBOBDadungA1p238D/ilt/yTwfyLpNPBmYDGApN8GzgfOiIgTgRHgIpKrwRdFxJsj4njgq+16w2bNzCo6gFnJ7ExXys1cV/Pzc02mPwRcK6mfpDsPSLpK+QOAiPh+usVwIMlgMeel7bdKeimd/53AycCPk+526CXpBO9/AUdK+nvgVuC2vXx/Zpl4y8Esu2hxf8x7gH8gWbnfn/amOVHXy81eQ8DVEXFielsaEZdHxEskg8j8b+BS4Mt7+R7MMnFxMMvu/Jqfd9dOkNQFHBYRd5EMkjQXeA3wQ5LdQkh6O/BCJGN31La/i6TTQEg6vXu/pIPTafMlHZ6eydQVETcCf0nSPblZbrxbyWy8XkkP1Dz+XkSMnc66n6R7Sb5UXVj3vG7gmnSXkYDPRcR2SZeTjFb3ELCDV7th/hRwnaSfAD8g6d6biPippDXAbWnBGSbZUtiZvs7YF7rVbXvHZk34VFazDHyqqVWNdyuZmVkDbzmYmVkDbzmYmVkDFwczM2vg4mBmZg1cHMzMrIGLg5mZNfj/qEuDZgZyydoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(0,num_episodes)]\n",
    "y = np.mean(rewards_avg, axis=0)\n",
    "plot.xlabel('Episodes')\n",
    "plot.ylabel('Reward')\n",
    "plot.plot(x, y,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********Q-table********\n",
      "\n",
      " [[-4.07348991 -3.63458601 -3.97054434 -3.55090977]\n",
      " [-4.50761455 -3.72575763 -3.63774587  4.38684219]\n",
      " [-4.16614092  5.6722987  -3.22166418 -2.64213672]\n",
      " [-3.2566078   7.02453829 -2.20194238 -2.68221486]\n",
      " [-3.2566078   2.47248677 -2.32663798 -2.14639856]\n",
      " [-2.6085155  -1.71807997 -1.96078351 -1.74568748]\n",
      " [-2.04755    -1.46334541 -1.48532329 -2.342795  ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-3.73894462 -3.7342522  -4.64105101  4.36035453]\n",
      " [ 2.94691563  4.80433166  2.88722205  5.51720101]\n",
      " [ 4.29378775  6.8837203   4.39047526  6.76618311]\n",
      " [ 5.48468455  8.14464514  5.57640968  8.1350657 ]\n",
      " [-1.51264204  9.51866254 -2.16712716 -1.97688584]\n",
      " [-1.7138035   0.36326167 -1.6454186  -1.59422772]\n",
      " [-1.3906017  -1.33122206 -1.4382598  -2.04755   ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-3.38265854 -3.41169872 -4.07348991 -3.04160789]\n",
      " [-2.75093076 -3.30390442 -3.46565434  6.75555101]\n",
      " [-1.10123781 -2.69971645 -2.72896603  8.36213568]\n",
      " [ 6.63380759  9.23940623  6.82917688  9.98816655]\n",
      " [ 8.09612451 11.80554799  8.2633559   7.60447939]\n",
      " [-1.34869076 10.20667122 -1.21988653 -1.31932027]\n",
      " [-1.03926595 -1.0475864  -1.06880206 -2.04755   ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-2.85202552 -2.81929283 -3.2566078  -2.74436038]\n",
      " [-2.87509129 -1.22464416 -2.85968665 -2.7264676 ]\n",
      " [-2.20765253 -1.99461474 -2.27988121  8.47559076]\n",
      " [ 4.97025657  2.62545875  1.00302682 11.32733186]\n",
      " [ 9.67621672 13.85246425  9.15800015 10.00772385]\n",
      " [-0.75895956 -0.29954264 11.39453347 -0.87431048]\n",
      " [-0.66238237 -0.72228884 -0.66463391 -1.78511   ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-2.31414261 -1.86431133 -3.06289756 -2.31906839]\n",
      " [-1.71420567 -1.7027172  -1.72963631  7.75831851]\n",
      " [ 0.79588656 12.32567484  1.03306171  4.88802635]\n",
      " [-0.20231048 -0.89194477 -1.16546473 13.69298104]\n",
      " [11.49579062 15.89908495  9.56115235 10.16808499]\n",
      " [-0.44203545 -0.36195    12.9262699  -0.39116283]\n",
      " [-0.34632878 -0.36195    -0.32156465 -0.5       ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-1.16207802  0.57379476 -1.7195     -1.12320133]\n",
      " [-1.04536324 12.58025    -1.21404257  0.24301243]\n",
      " [ 2.05042154 14.295       1.32775792  6.33673496]\n",
      " [ 5.21914584 16.1         4.52559176  9.70653927]\n",
      " [13.22927284 18.         12.48820614 11.83535809]\n",
      " [-0.20805    15.23720506 -0.28905    -0.1995    ]\n",
      " [-0.32169512 -0.17476217 -0.1095     -0.1       ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-1.10479567 -0.5217031  -2.84766395  7.96282538]\n",
      " [ 0.49998379 -0.61868415  1.09354882 14.295     ]\n",
      " [ 9.12566944  3.23405958  6.78335725 16.1       ]\n",
      " [12.149382   11.16048001 12.89568346 18.        ]\n",
      " [15.94691694 20.         16.01010691 16.03553121]\n",
      " [-0.21810511 -0.19       17.99923511 -0.19      ]\n",
      " [-0.1        -0.1         1.62550188 -0.5       ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.46964898 -0.271      -0.5        -0.2166    ]\n",
      " [-0.43178556 -0.41901    -0.29841225  1.29511483]\n",
      " [-0.2885903  -0.271      -0.36195    11.06234183]\n",
      " [ 1.51999623 -0.1        -0.1806805  19.15217683]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.1        -0.1         2.          0.        ]\n",
      " [-0.1         0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.1        -0.5        -0.5        -0.1095    ]\n",
      " [-0.21647603 -0.95       -0.1        -0.1       ]\n",
      " [-0.2976     -0.95        0.          0.        ]\n",
      " [ 0.          0.         -0.1         0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.1         0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\\n********Q-table********\\n\\n {q_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GameEnviroment:\n",
    "    def __init__(self, map, size, player_initial_state, goal_position):\n",
    "        self.map = map\n",
    "        self.size = size\n",
    "        self.player_state = player_initial_state\n",
    "        self.goal = goal_position \n",
    "        self.rewards = {\n",
    "            \"walk\": -1,\n",
    "            \"fall\": -5,\n",
    "            \"goal\": 20\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.map) + f\"\\nPlayerPos: ({self.player_state[0]}, {self.player_state[1]})\"\n",
    "    \n",
    "    def reset(self, initial_map, player_initial_state):\n",
    "        self.map = initial_map\n",
    "        self.player_state = player_initial_state\n",
    "        return ((10 * self.player_state[0]) + self.player_state[1])\n",
    "\n",
    "    def is_in_goal(self):\n",
    "        return (self.player_state[0] == self.goal[0] and self.player_state[1] == self.goal[1])\n",
    "    \n",
    "    def has_fallen_of_map(self):\n",
    "        x_range = np.array(range(self.size[0]))\n",
    "        y_range = np.array(range(self.size[1]))\n",
    "        return (self.player_state[1] not in y_range or self.player_state[0] not in x_range)\n",
    "\n",
    "    def move_player_left(self):\n",
    "        self.player_state[0] = self.player_state[0] - 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "    \n",
    "    def move_player_right(self):\n",
    "        self.player_state[0] = self.player_state[0] + 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "\n",
    "    def move_player_up(self):\n",
    "        self.player_state[1] = self.player_state[1] - 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "    \n",
    "    def move_player_down(self):\n",
    "        self.player_state[1] = self.player_state[1] + 1\n",
    "        if self.is_in_goal():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"goal\"], True\n",
    "        if self.has_fallen_of_map():\n",
    "            return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"fall\"], True\n",
    "        self.map = draw_map(self.size, self.player_state, self.goal)\n",
    "        return (10*self.player_state[0] + self.player_state[1]), self.rewards[\"walk\"], False\n",
    "        \n",
    "    # 0 = LEFT, 1 = RIGHT, 2 = UP, 3 = DOWN\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            new_state, reward, done = self.move_player_left()\n",
    "        if action == 1:\n",
    "            new_state, reward, done = self.move_player_right()\n",
    "        if action == 2:\n",
    "            new_state, reward, done = self.move_player_up()\n",
    "        if action == 3:\n",
    "            new_state, reward, done = self.move_player_down()\n",
    "\n",
    "        # now we dont have wind :)\n",
    "        \n",
    "        return new_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_size = [9, 7]\n",
    "player_initial_pos = [1, 1]\n",
    "goal_pos = [7, 4]\n",
    "\n",
    "initial_map = draw_map(map_size, player_initial_pos, goal_pos)\n",
    "env = GameEnviroment(initial_map, map_size, player_initial_pos, goal_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 15000\n",
    "max_steps_per_episode = 200\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount_rate = 0.95\n",
    "\n",
    "rewards_avg = []\n",
    "\n",
    "action_space_size = 4\n",
    "state_space_size = 200\n",
    "\n",
    "q_table = np.zeros((state_space_size, action_space_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average  0\n",
      "average  1\n",
      "average  2\n",
      "average  3\n",
      "average  4\n",
      "average  5\n",
      "average  6\n",
      "average  7\n",
      "average  8\n",
      "average  9\n",
      "average  10\n",
      "average  11\n",
      "average  12\n",
      "average  13\n",
      "average  14\n",
      "average  15\n",
      "average  16\n",
      "average  17\n",
      "average  18\n",
      "average  19\n",
      "average  20\n",
      "average  21\n",
      "average  22\n",
      "average  23\n",
      "average  24\n",
      "average  25\n",
      "average  26\n",
      "average  27\n",
      "average  28\n",
      "average  29\n",
      "average  30\n",
      "average  31\n",
      "average  32\n",
      "average  33\n",
      "average  34\n",
      "average  35\n",
      "average  36\n",
      "average  37\n",
      "average  38\n",
      "average  39\n",
      "average  40\n",
      "average  41\n",
      "average  42\n",
      "average  43\n",
      "average  44\n",
      "average  45\n",
      "average  46\n",
      "average  47\n",
      "average  48\n",
      "average  49\n",
      "average  50\n",
      "average  51\n",
      "average  52\n",
      "average  53\n",
      "average  54\n",
      "average  55\n",
      "average  56\n",
      "average  57\n",
      "average  58\n",
      "average  59\n",
      "average  60\n",
      "average  61\n",
      "average  62\n",
      "average  63\n",
      "average  64\n",
      "average  65\n",
      "average  66\n",
      "average  67\n",
      "average  68\n",
      "average  69\n",
      "average  70\n",
      "average  71\n",
      "average  72\n",
      "average  73\n",
      "average  74\n",
      "average  75\n",
      "average  76\n",
      "average  77\n",
      "average  78\n",
      "average  79\n",
      "average  80\n",
      "average  81\n",
      "average  82\n",
      "average  83\n",
      "average  84\n",
      "average  85\n",
      "average  86\n",
      "average  87\n",
      "average  88\n",
      "average  89\n",
      "average  90\n",
      "average  91\n",
      "average  92\n",
      "average  93\n",
      "average  94\n",
      "average  95\n",
      "average  96\n",
      "average  97\n",
      "average  98\n",
      "average  99\n"
     ]
    }
   ],
   "source": [
    "# This cycle is to calculate the average reward/episodes and its only purpose is to plot the nice graph below that\n",
    "# shows how the agent learn how to maximize the reward.\n",
    "for it in range(100):\n",
    "    print('average ', it)\n",
    "    rewards_all_episodes=[]\n",
    "    \n",
    "    # exporation-exploitation trade-off params\n",
    "    exploration_rate = 1\n",
    "    max_exploration_rate = 1\n",
    "    min_exploration_rate = 0.01\n",
    "    exploration_decay_rate = 0.005\n",
    "    \n",
    "    # init q table in zeros\n",
    "    q_table = np.zeros((state_space_size, action_space_size))\n",
    "\n",
    "    # iterate over the episodes\n",
    "    for episode in range(num_episodes):\n",
    "        player_initial_pos = [1, 1]\n",
    "        initial_map = draw_map(map_size, player_initial_pos, goal_pos)\n",
    "        state = env.reset(initial_map, player_initial_pos)\n",
    "        done = False\n",
    "        rewards_current_episode = 0\n",
    "        \n",
    "        # iterate over the steps for an episode\n",
    "        for step in range(max_steps_per_episode):\n",
    "            # Exploration-exploitation trade-off\n",
    "            exploration_rate_threshold = np.random.uniform(low=0.0, high=1.0)\n",
    "            if exploration_rate_threshold <= exploration_rate:\n",
    "                # Expl oration time\n",
    "                action = np.random.randint(0, action_space_size)\n",
    "            else:\n",
    "                # Explotation time\n",
    "                action = np.argmax(q_table[state])\n",
    "\n",
    "            # Take action\n",
    "            new_state, reward, done = env.step(action)\n",
    "\n",
    "            # Update Q-table for Q(s,a)\n",
    "            q_table[state, action] = (1 - learning_rate) * q_table[state, action] + learning_rate * (reward + discount_rate * np.max(q_table[new_state]))\n",
    "            # transition next state\n",
    "\n",
    "            state = new_state\n",
    "            rewards_current_episode += reward\n",
    "\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "\n",
    "        # Exploration rate decay\n",
    "        exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate) * (math.e ** (-exploration_decay_rate * episode))\n",
    "\n",
    "        rewards_all_episodes.append(rewards_current_episode)\n",
    "    rewards_avg.append(rewards_all_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x296d02c21f0>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(0,num_episodes)]\n",
    "y = np.mean(rewards_avg, axis=0)\n",
    "plot.xlabel('Episodes')\n",
    "plot.ylabel('Reward')\n",
    "plot.plot(x, y,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********Q-table********\n",
      "\n",
      " [[-3.85616038 -2.84938895 -3.72906709 -2.80887875]\n",
      " [-4.60116778  5.14873853 -2.9709562  -2.94010187]\n",
      " [-4.24952682 -2.55185106 -2.64916387  6.19744483]\n",
      " [-3.97054434  7.93058448 -2.03602034 -1.98109294]\n",
      " [-3.43094702 -1.4900982  -1.59720563 -1.50022629]\n",
      " [-2.6085155  -1.16322704 -1.24470555 -1.21398941]\n",
      " [-0.95       -1.05862192 -1.03204769 -1.355     ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-3.0067344  -3.0302663  -4.60116778  5.09697665]\n",
      " [ 3.64596359  3.64985671  3.36123411  6.53681725]\n",
      " [ 3.89257344  7.70538701  4.98411572  7.93349184]\n",
      " [ 6.23690712  9.40367562  6.47547449  8.90543568]\n",
      " [-1.65031328 10.86808601 -1.44666192 -1.4743305 ]\n",
      " [-1.16813958 -1.203044   -1.18164784 -1.2190704 ]\n",
      " [-0.97926949 -0.97577074 -1.05368046 -2.04755   ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-2.62103412 -2.60655618 -2.6085155  -2.58504953]\n",
      " [ 5.15963583 -2.49775665 -2.76520042 -1.97396569]\n",
      " [ 0.50610588 -1.42617839 -2.36822075  9.40325411]\n",
      " [ 7.90215269 10.9512375   7.86435637 10.84846531]\n",
      " [ 0.15778846 12.58024364 -0.70487991 -1.09011482]\n",
      " [-1.15863495 -0.95546391  2.9701581  -0.97899889]\n",
      " [-0.76694977 -0.83691943 -0.85205441 -2.342795  ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-2.11784969 -2.04962933 -4.16614092 -2.00715199]\n",
      " [-2.18503493 -2.00825467 -2.04550396 -0.54018981]\n",
      " [-1.08723933 -1.03257298 -1.83004394 10.92288373]\n",
      " [ 9.25007553 12.52845158  9.20767353 12.58025   ]\n",
      " [10.64926491 14.295      10.92973925 10.67574548]\n",
      " [-0.53811301 12.53465081  0.46111217 -0.75216549]\n",
      " [-0.622019   -0.65457353 -0.75068909 -1.355     ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-1.61529297 -1.49491627 -2.84766395 -1.53576653]\n",
      " [-1.69259188 -1.40830649 -1.3849402  -1.13172188]\n",
      " [-0.91078812 -1.00676695 -1.02938878  4.5219701 ]\n",
      " [ 0.39816644 -0.11464232 -0.46882447 14.29483723]\n",
      " [12.52462445 16.1        12.3652295  12.52410253]\n",
      " [-0.28972527  0.57613507 14.29494686 -0.51614762]\n",
      " [-0.50550756 -0.52061947  2.94847642 -1.355     ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-1.09774967 -0.97418352 -2.04755    -0.95640434]\n",
      " [-1.16453062 -0.79228152 -0.95330684 -0.37283163]\n",
      " [-0.771218   -0.58378261 -0.65060102  3.71631067]\n",
      " [ 1.55744052 16.05253817 -0.12660452 -0.3193075 ]\n",
      " [14.27116584 18.         13.9852323  14.08698429]\n",
      " [ 1.34418002  0.83296298 16.07000246 -0.19      ]\n",
      " [-0.39884242 -0.1995      0.98004183 -0.5       ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.58887255 -0.41901    -2.04755    -0.42649793]\n",
      " [-0.66951161 -0.473308   -0.393585    1.32068406]\n",
      " [-0.26578055 -0.27906265 -0.29507109  9.58681256]\n",
      " [ 0.60744581  3.09090104  2.91074701 17.99998653]\n",
      " [16.08334302 20.         16.08404469 15.94292177]\n",
      " [ 0.72068887  0.         17.97946481 -0.435255  ]\n",
      " [-0.1995     -0.19        0.72859959 -0.95      ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.2814025  -0.19       -0.5        -0.10363555]\n",
      " [-0.24204568 -0.19       -0.1         0.05830685]\n",
      " [-0.28494818 -0.1        -0.1         2.7061909 ]\n",
      " [ 0.21142208 -0.1        -0.038269   13.0264312 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.1        -0.1         0.         -0.5       ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.1        -0.5         0.         -0.19      ]\n",
      " [-0.10363555  0.         -0.19       -0.1       ]\n",
      " [-0.1        -0.5         0.          0.        ]\n",
      " [-0.1         0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.1         0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\\n********Q-table********\\n\\n {q_table}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25c701cf35b356b2d4bd1cf9d31da66e110c57249d3d7829e193c9302586500a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
